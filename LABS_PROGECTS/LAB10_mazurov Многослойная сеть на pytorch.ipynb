{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2590c9c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, \n",
    "                             recall_score, f1_score, confusion_matrix, \n",
    "                             classification_report)\n",
    "\n",
    "# 1. Улучшенная генерация данных с разделением на train/test\n",
    "def generate_spiral_data(samples_per_class=100, n_classes=3, noise=0.2, test_size=0.2):\n",
    "    X = np.zeros((samples_per_class * n_classes, 2))\n",
    "    y = np.zeros(samples_per_class * n_classes, dtype='uint8')\n",
    "    \n",
    "    for class_id in range(n_classes):\n",
    "        ix = range(samples_per_class * class_id, samples_per_class * (class_id + 1))\n",
    "        r = np.linspace(0.0, 1, samples_per_class)\n",
    "        t = np.linspace(class_id * 4, (class_id + 1) * 4, samples_per_class) + np.random.randn(samples_per_class) * noise\n",
    "        X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "        y[ix] = class_id\n",
    "    \n",
    "    # Разделение на train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Генерация данных\n",
    "X_train, X_test, y_train, y_test = generate_spiral_data(noise=0.3)\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Визуализация данных\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', edgecolors='k')\n",
    "plt.title('Обучающая выборка')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='viridis', edgecolors='k')\n",
    "plt.title('Тестовая выборка')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Конфигурация обучения\n",
    "class TrainingConfig:\n",
    "    batch_size = 64\n",
    "    epochs = 1000\n",
    "    learning_rate = 1e-3\n",
    "    hidden_size = 100\n",
    "    early_stop_patience = 20\n",
    "\n",
    "# 3. Универсальная функция обучения\n",
    "def train_model(model, X_train, y_train, X_test, y_test, config):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Преобразование данных в тензоры\n",
    "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_t = torch.LongTensor(y_train).to(device)\n",
    "    X_test_t = torch.FloatTensor(X_test).to(device)\n",
    "    y_test_t = torch.LongTensor(y_test).to(device)\n",
    "    \n",
    "    # Оптимизатор и планировщик\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Логирование\n",
    "    train_loss, test_loss = [], []\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        # Обучение\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_t)\n",
    "            t_loss = criterion(test_outputs, y_test_t)\n",
    "        \n",
    "        # Логирование\n",
    "        train_loss.append(loss.item())\n",
    "        test_loss.append(t_loss.item())\n",
    "        scheduler.step(t_loss)\n",
    "        \n",
    "        # Ранняя остановка\n",
    "        if t_loss < best_loss:\n",
    "            best_loss = t_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= config.early_stop_patience:\n",
    "            print(f\"Ранняя остановка на эпохе {epoch}\")\n",
    "            break\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch:4d} | Train Loss: {loss.item():.4f} | Test Loss: {t_loss.item():.4f}\")\n",
    "    \n",
    "    return train_loss, test_loss\n",
    "\n",
    "# 4. Модели\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(2, TrainingConfig.hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(TrainingConfig.hidden_size, 3)\n",
    ")\n",
    "\n",
    "deep_net = nn.Sequential(\n",
    "    nn.Linear(2, TrainingConfig.hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(TrainingConfig.hidden_size, TrainingConfig.hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(TrainingConfig.hidden_size, TrainingConfig.hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(TrainingConfig.hidden_size, 3)\n",
    ")\n",
    "\n",
    "# 5. Обучение моделей\n",
    "print(\"\\nОбучение простой модели:\")\n",
    "train_loss_simple, test_loss_simple = train_model(simple_net, X_train, y_train, X_test, y_test, TrainingConfig)\n",
    "\n",
    "print(\"\\nОбучение глубокой модели:\")\n",
    "train_loss_deep, test_loss_deep = train_model(deep_net, X_train, y_train, X_test, y_test, TrainingConfig)\n",
    "\n",
    "# 6. Визуализация процесса обучения\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_loss_simple, label='Простая модель (train)')\n",
    "plt.plot(test_loss_simple, '--', label='Простая модель (test)')\n",
    "plt.plot(train_loss_deep, label='Глубокая модель (train)')\n",
    "plt.plot(test_loss_deep, '--', label='Глубокая модель (test)')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.ylabel('Потери')\n",
    "plt.title('Кривые обучения')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7. Функция оценки модели\n",
    "def evaluate_model(model, X, y_true):\n",
    "    device = next(model.parameters()).device\n",
    "    X_t = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_t).cpu().numpy()\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis', alpha=0.6, edgecolors='k')\n",
    "    plt.title('Предсказания модели')\n",
    "    plt.show()\n",
    "\n",
    "# Оценка моделей\n",
    "print(\"\\nОценка простой модели на тестовых данных:\")\n",
    "evaluate_model(simple_net, X_test, y_test)\n",
    "\n",
    "print(\"\\nОценка глубокой модели на тестовых данных:\")\n",
    "evaluate_model(deep_net, X_test, y_test)\n",
    "\n",
    "# 8. Визуализация границ решений\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    grid_tensor = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Z = model(grid_tensor).cpu().numpy()\n",
    "    Z = np.argmax(Z, axis=1).reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(simple_net, X_test, y_test, 'Простая модель')\n",
    "plot_decision_boundary(deep_net, X_test, y_test, 'Глубокая модель')\n",
    "\n",
    "# 9. Сравнение метрик\n",
    "def compare_metrics(models, model_names, X_test, y_test):\n",
    "    results = []\n",
    "    for model, name in zip(models, model_names):\n",
    "        X_t = torch.FloatTensor(X_test).to(next(model.parameters()).device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_t).cpu().numpy()\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        results.append({\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'F1': f1_score(y_test, y_pred, average='weighted')\n",
    "        })\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    for i, (res, name) in enumerate(zip(results, model_names)):\n",
    "        plt.bar(x + i*width/2, [res[m] for m in metrics], width=width, label=name)\n",
    "    \n",
    "    plt.xticks(x, metrics)\n",
    "    plt.ylim(0.8, 1.0)\n",
    "    plt.title('Сравнение метрик качества')\n",
    "    plt.ylabel('Значение')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "compare_metrics([simple_net, deep_net], ['Простая', 'Глубокая'], X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mazurov_3_11_ten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
